Here are the features of the two mode of flipped learning app.
1.  The chatbot will ask a set of questions related to the topic, which can be short questions, multiple-choice, or reflective question. For each question, 3 hints will be provided, along with a model answer and an explanation. The student must answer pre-defined minimum number of questions correctly to complete the topic. The instructors can define the type of questions that will be generated and the number of questions that the student should correctly answer to complete the topic. For multiple choice questions, the instructor can configure whether the chatbot should ask the student to explain their choice before providing feedback or moving to the next question.

For each topic, outuput the topic name, detailed topic summary, timestamp,
Also generate the discussion items and various types of questions (3 mcq, 2 short questions, 2 reflective questions for each topic) based on the video transcript provided below.
For discussion item, it short start from simple questions to more complex question.
Each discussion item should provide and sample answer 
For each question assign a point value (e.g., 1 point for mcq, 2 points for short questions, 3 points for reflective questions, 2 points for each discusson item). Each question or discuss item should output the question, point value, and sample answer, and the reference timestamp in the video transcript that contain the answer to the question. Each question should provide 3 hints, correct answer and explanation of the correct answer.


Requirements:
-  The first 3 topics has a field which indicates it's "Required = True", while the other required=false.
- For each topic, generate 6 questions. The first 3 questions is core while the other are optional
- For each topic, there will be core questions that user should complete.
Core questions:
- the first core question should be a discussion item (there is no answer but a rubric for evaluation), which means that it does not have right or wrong answer. E.g. ask which technology is most useful to student.
question 2 will be mcq questions
- question 4 will be reflective question on the topic.
- Other questions should be optional questions.
- Each topic name should be 4-5 words
- 


# Output in Json Format without ```json

Example:
{
  "topics": [
    {
      "title": "Introduction to Machine Learning Applications",
      "required": true, # indicates this topic is core topic
      "start_timestamp": "00:01",
      "end_timestamp": "00:39",
      "summary": "..."
      "questions": [
        {
          "type": "discussion",
          "required": true,
          "question": "What are some real-world applications of machine learning that you find most interesting?",
          "point_value": 2,
          "evaluation_criteria": "Discuss the applications mentioned in the video and any additional ones you know.",
        }
        {
          "type": "mcq",
          "required": true
          "question": "Which of the following is NOT mentioned as an application of machine learning?",
          "point_value": 1,
          "options": ["Detecting skin cancer", "Sorting cucumbers", "Detecting escalators needing repair", "Playing chess"],
          "correct_answer": "Playing chess",
          "explanation": "The video mentions detecting skin cancer, sorting cucumbers, and escalator repair but does not mention playing chess.",
          "hints": [
            "..",
            ...
          ],
          "reference_timestamp": "00:01"
        },
        {
          "type": "short", # short question
          "question": "Why is machine learning important in real-world applications?",
          "point_value": 2,
          "sample_answer": "Because it allows computer systems to perform tasks that are difficult to program manually by learning from data.",
          "explanation": "Machine learning helps automate complex decision-making and pattern recognition tasks by using data instead of explicit rules.",
          "hints": [
            "Think about tasks that are hard to code.",
            "Learning from data is key.",
            "It enables automation."
          ],
          "reference_timestamp": "00:01-00:20"
        }
        {
          "type": "reflective",
          "question": "How might machine learning change traditional approaches to problem-solving in technology?",
          "point_value": 3,
          "sample_answer": "Machine learning shifts problem-solving from manual programming of rules to building models that learn patterns from data, enabling systems to adapt and handle complex tasks more efficiently.",
          "explanation": "This reflects the paradigm shift from rule-based programming to data-driven learning enabling greater flexibility and automation.",
          "hints": [
            "Consider the difference between programming rules and learning.",
            "Think about adaptability and automation.",
            "Reflect on the complexity of tasks."
          ],
          "reference_timestamp": "00:20"
        }
      ]
    },
    ...
  ]
}



# topics
{
  "topics": [
    {
      "title": "Machine Learning Basics",
      "learning_objectives": [
        "Understand real-world uses of machine learning",
        "Know what a model is and what training means",
        "Recognize the idea of using features to answer questions"
      ],
      "start_timestamp": "00:01",
      "end_timestamp": "00:39",
      "detailed_summary": "The video starts by explaining that machine learning gives computers new abilities, like detecting skin cancer or sorting cucumbers. The host introduces the main question: how does machine learning actually work? As an example, the video sets up a problem where a computer must decide if a drink is wine or beer. The system built to answer this question is called a 'model,' and creating it is called 'training'. The goal of training is to make a model that answers correctly most of the time."
    },
    {
      "title": "Data Collection",
      "learning_objectives": [
        "Understand the importance of quality data",
        "Learn how to select features for machine learning",
        "Know the process of gathering and measuring data"
      ],
      "start_timestamp": "00:39",
      "end_timestamp": "01:54",
      "detailed_summary": "To train a model, we need data. The video explains that you collect data from glasses of wine and beer, measuring two features: color (as a wavelength of light) and alcohol content (as a percentage). These features are chosen because they might help separate wines from beers. Equipment like a spectrometer and hydrometer are used to gather this data. The quality and amount of data directly affects how good the model can be."
    },
    {
      "title": "Data Preparation",
      "learning_objectives": [
        "Understand the need for data preparation before training",
        "Know about data randomization, visualization, and splitting",
        "Learn the importance of balanced data and cleaning"
      ],
      "start_timestamp": "01:54",
      "end_timestamp": "03:43",
      "detailed_summary": "After collecting data, you must prepare it for training. This involves combining all measurements, randomizing their order, and visualizing the data to spot relationships or imbalances (like having more beer than wine samples). It's also important to split the data into training and evaluation sets, so the model is tested fairly. Other preparation steps can include deduplication and normalization, but for this simple example, those are not needed."
    },
    {
      "title": "Model Choice & Training",
      "learning_objectives": [
        "Know how to select an appropriate model",
        "Understand how training works using data",
        "Learn about weights, biases, and iterative improvement"
      ],
      "start_timestamp": "03:43",
      "end_timestamp": "06:24",
      "detailed_summary": "Choosing a model depends on the features and type of data. Here, a simple linear model is used, which can separate wine and beer using a line. Training means adjusting the model's parameters (weights and biases) to improve its predictions, similar to how someone gets better at driving with practice. The process starts with random guesses and then iteratively updates the model so that predictions become more accurate over time."
    },
    {
      "title": "Evaluation & Prediction",
      "learning_objectives": [
        "Learn how to evaluate model performance",
        "Understand hyperparameter tuning",
        "Know the final steps to make predictions"
      ],
      "start_timestamp": "06:24",
      "end_timestamp": "10:05",
      "detailed_summary": "After training, the model is evaluated using the set-aside data to see how well it works on new, unseen examples. The video discusses tuning parameters like learning rate and training steps (called hyperparameters) to further improve results. Once the model is performing well, it can be used to make predictions, like deciding if a new drink is wine or beer. The process described can be applied to other problems beyond drinks, showing the general steps of machine learning."
    }
  ]
}

# video contents
The 7 steps of machine learning - YouTube
https://www.youtube.com/watch?v=nKW8Ndu7Mjw

Transcript:
(00:01) from detecting skin cancer to sorting cucumbers to detecting escalators in need of repair machine learning has granted computer systems entirely new abilities but how does it really work under the hood let's walk through a basic example and use it as an excuse to talk about the process of getting answers from your data using machine learning welcome to cloud ai adventures my name is eufan guo on this show we'll explore the art science and tools of machine learning let's pretend that we've been asked to create a system that answers the question of whether a drink is wine or beer this question answering system that we
(00:39) build is called a model and this model is created via a process called training machine learning the goal of training is to create an accurate model that answers our questions correctly most of the time but in order to train a model we need to collect data to train on this is where we will begin our data will be collected from glasses of wine and beer there are many aspects of drinks that we could collect data on everything from the amount of foam to the shape of the glass but for our purposes we'll just pick two simple ones the color as a wavelength of light and the alcohol content as a percentage the hope is that we can split our two
(01:18) types of drinks along these two factors alone we'll call these our features from now on color and alcohol the first step to our process will be to run out to the local grocery store buy up a bunch of different drinks and get some equipment to do our measurements a spectrometer for measuring the color and a hydrometer to measure the alcohol content it appears that our grocery store has an electronics hardware section as well once our equipment and booze we got it all set up it's time for our first real step of machine learning gathering that data this step is very important because the quality and quantity of data
(01:54) that you gather will directly determine how good your predictive model can be in this case the data we collect will be the color and alcohol content of each drink this will yield us a table of color alcohol content and whether it's beer or wine this will be our training data so a few hours of measurements later we've gathered our training data and had a few drinks perhaps and now it's time for our next step of machine learning data preparation where we load our data into a suitable place and prepare it for use in our machine learning training we'll first put all our data together then randomize the ordering
(02:35) we wouldn't want the order of our data to affect how we learn since that's not part of determining whether a drink is beer or wine in other words we want to make a determination of what a drink is independent of what drink came before or after in the sequence this is also a good time to do any pertinent visualizations of your data helping you see if there's any relevant relationships between different variables as well as show you if there are any data imbalances for instance if we collected way more data points about beer than wine the model we train will be heavily biased toward guessing that virtually
(03:08) everything it sees is beer since it would be right most of the time however in the real world the model may see beer and wine an equal amount which would mean that it would be guessing beer wrong half the time we also need to split the data into two parts the first part used in training our model will be the majority of our data set the second part will be used for evaluating our trained model's performance we don't want to use the same data that the model was trained on for evaluation since then it would just be able to memorize the questions just as you wouldn't want to use the questions from your math homework on the
(03:43) math exam sometimes the data we collect needs other forms of adjusting and manipulation things like deduplication normalization error correction and others these would all happen at the data preparation step in our case we don't have any further data preparation needs so let's move on forward the next step in our workflow is choosing a model there are many models that researchers and data scientists have created over the years some are very well suited for image data others for sequences such as text or music some for numerical data and others for text-based data in our case we have just two features color and alcohol percentage we can use
(04:25) a small linear model which is a fairly simple one that'll get the job done now we move on to what is often considered the bulk of machine learning the training in this step we'll use our data to incrementally improve our model's ability to predict whether a given drink is wine or beer in some ways this is similar to someone first learning to drive at first they don't know how any of the pedals knobs and switches work or when they should be pressed or used however after lots of practice and correcting for their mistakes a licensed driver emerges moreover after a year of driving they've become quite adept at driving
(05:04) the act of driving and reacting to real world data has adapted their driving abilities honing their skills we will do this on a much smaller scale with our drinks in particular the formula for a straight line is y equals mx plus b where x is the input m is the slope of the line b is the y y-intercept and y is the value of the line at that position x the values we have available to us to adjust or train are just m and b where the m is that slope and b is the y-intercept there's no other way to affect the position of the line since the only other variables are x our input and y our output in machine learning there are many m's
(05:48) since there may be many features the collection of these values is usually formed into a matrix that is denoted w for the weights matrix similarly for b we arrange them together and that's called the biases the training process involves initializing some random values for w and b and attempting to predict the outputs with those values as you might imagine it does pretty poorly at first but we can compare our model's predictions with the output that it should have produced and adjust the values in w and b such that we will have more accurate predictions on the next time around so this process then repeats each
(06:24) iteration or cycle of updating the weights and biases is called one training step so let's look at what that means more concretely for our data set when we first start the training it's like we drew a random line through the data then as each step of the training progresses the line moves step by step closer to the ideal separation of the wine and beer once training is complete it's time to see if the model is any good using evaluation this is where that data set that we set aside earlier comes into play evaluation allows us to test our model against data that has never been used for training this metric allows us to see how the
(07:01) model might perform against data that has not yet seen this is meant to be representative of how the model might perform in the real world a good rule of thumb i use for a training evaluation split is somewhere on the order of 80 20 or 70 30. much of this depends on the size of the original source data set if you have a lot of data perhaps you don't need as big of a fraction for the evaluation data set once you've done evaluation it's possible that you want to see if you can further improve your training in any way we can do this by tuning some of our parameters there were a few that we implicitly assumed when we did our training and now
(07:38) is a good time to go back and test those assumptions try other values one example of a parameter we can tune is how many times we run through the training set during training we can actually show the data multiple times so by doing that we will potentially lead to higher accuracies another parameter is learning rate this defines how far we shift the line during each step based on the information from the previous training step these values all play a role in how accurate our model can become and how long the training takes for more complex models initial conditions can play a significant role as well in determining
(08:16) the outcome of training differences can be seen depending on whether a model starts off training with values initialized to zeros versus some distribution of values and what that distribution is as you can see there are many considerations at this phase of training and it's important that you define what makes a model good enough for you otherwise we might find ourselves tweaking parameters for a very long time now these parameters are typically referred to as hyper parameters the adjustment or tuning of these hyper parameters still remains a bit more of an art than science and it's an experimental process that
(08:51) heavily depends on the specifics of your data set model and training process once you're happy with your training and hyper parameters guided by the evaluation step it's finally time to use your model to do something useful machine learning is using data to answer questions so prediction or inference is that step where we finally get to answer some questions this is the point of all of this work where the value of machine learning is realized we can finally use our model to predict whether a given drink is wine or beer given its color and alcohol percentage the power of machine learning is that we were able to determine this
(09:28) and how to differentiate between wine and beer using our model rather than using human judgment and manual rules you can extrapolate the ideas presented today to other problem domains as well where the same principles apply gathering data preparing that data choosing a model training it and evaluating it doing your hyper parameter tuning and finally prediction if you're looking for more ways to play with training and parameters check out the tensorflow playground it's a completely browser-based machine learning sandbox where you can try different parameters and run training against mock data sets and don't worry you can't break the site
(10:05) of course we'll encounter more steps and nuances in future episodes but this serves as a good foundational framework to help us think through the problem giving us a common language to think about each step and go deeper in the future next time on ai adventures we will build our first real machine learning model using code no more drawing lines and going over algebra